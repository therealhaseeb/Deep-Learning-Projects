{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"sonar.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(Y)\n",
    "encoded_Y = le.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model, write code below\n",
    "def create_baseline():\n",
    "    network = Sequential()\n",
    "    network.add(Dense(60, activation='relu', input_dim=60))\n",
    "    network.add(Dense(1, activation='sigmoid'))\n",
    "   \n",
    "    # Compile model, write code below\n",
    "    network.compile(optimizer='Adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 83.71% (6.13%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 85.59% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # smaller model\n",
    "# def create_smaller():\n",
    "#     # create model, write code below\n",
    "#     network = Sequential()\n",
    "#     network.add(Dense(30, activation='relu', input_dim=60))\n",
    "#     network.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "   \n",
    "#     # Compile model, write code below\n",
    "#     network.compile(optimizer='Adam',\n",
    "#                 loss='binary_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "#     return network    \n",
    "    \n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "\n",
    "# pipeline = Pipeline(estimators)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "# print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # larger model\n",
    "# def create_larger():\n",
    "#     # create model, write code below\n",
    "#     network = Sequential()\n",
    "#     network.add(Dense(60, activation='relu', input_dim=60))\n",
    "#     network.add(Dense(30, activation='sigmoid'))\n",
    "#     network.add(Dense(1, activation='sigmoid'))\n",
    "   \n",
    "#     # Compile model, write code below\n",
    "#     network.compile(optimizer='Adam',\n",
    "#                 loss='binary_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "#     return network    \n",
    "\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "\n",
    "# pipeline = Pipeline(estimators)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "# print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "208/208 [==============================] - 2s 8ms/step - loss: 0.6822 - acc: 0.6010\n",
      "Epoch 2/50\n",
      "208/208 [==============================] - 0s 460us/step - loss: 0.6541 - acc: 0.6250\n",
      "Epoch 3/50\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.6317 - acc: 0.6875\n",
      "Epoch 4/50\n",
      "208/208 [==============================] - 0s 487us/step - loss: 0.6064 - acc: 0.7500\n",
      "Epoch 5/50\n",
      "208/208 [==============================] - 0s 440us/step - loss: 0.5862 - acc: 0.6971\n",
      "Epoch 6/50\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.5734 - acc: 0.7404\n",
      "Epoch 7/50\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.5471 - acc: 0.7692\n",
      "Epoch 8/50\n",
      "208/208 [==============================] - 0s 480us/step - loss: 0.5335 - acc: 0.7500\n",
      "Epoch 9/50\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.5238 - acc: 0.7981\n",
      "Epoch 10/50\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.5038 - acc: 0.7644\n",
      "Epoch 11/50\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.4946 - acc: 0.8125\n",
      "Epoch 12/50\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.4790 - acc: 0.8413\n",
      "Epoch 13/50\n",
      "208/208 [==============================] - 0s 658us/step - loss: 0.4714 - acc: 0.8125\n",
      "Epoch 14/50\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.4593 - acc: 0.8317\n",
      "Epoch 15/50\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.4510 - acc: 0.8221\n",
      "Epoch 16/50\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.4411 - acc: 0.8317\n",
      "Epoch 17/50\n",
      "208/208 [==============================] - 0s 446us/step - loss: 0.4440 - acc: 0.8317\n",
      "Epoch 18/50\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.4295 - acc: 0.8173 0s - loss: 0.3929 - acc: 0.875\n",
      "Epoch 19/50\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.4235 - acc: 0.8269\n",
      "Epoch 20/50\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.4126 - acc: 0.8413\n",
      "Epoch 21/50\n",
      "208/208 [==============================] - 0s 474us/step - loss: 0.4105 - acc: 0.8413\n",
      "Epoch 22/50\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.4024 - acc: 0.8413\n",
      "Epoch 23/50\n",
      "208/208 [==============================] - 0s 478us/step - loss: 0.3997 - acc: 0.8173\n",
      "Epoch 24/50\n",
      "208/208 [==============================] - 0s 643us/step - loss: 0.3875 - acc: 0.8365\n",
      "Epoch 25/50\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.3811 - acc: 0.8413\n",
      "Epoch 26/50\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.3820 - acc: 0.8365\n",
      "Epoch 27/50\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.3807 - acc: 0.8365\n",
      "Epoch 28/50\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.3725 - acc: 0.8558\n",
      "Epoch 29/50\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.3633 - acc: 0.8510\n",
      "Epoch 30/50\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.3632 - acc: 0.8317\n",
      "Epoch 31/50\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.3595 - acc: 0.8413\n",
      "Epoch 32/50\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.3557 - acc: 0.8606\n",
      "Epoch 33/50\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.3464 - acc: 0.8558\n",
      "Epoch 34/50\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.3449 - acc: 0.8558\n",
      "Epoch 35/50\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.3409 - acc: 0.8558\n",
      "Epoch 36/50\n",
      "208/208 [==============================] - 0s 514us/step - loss: 0.3449 - acc: 0.8606\n",
      "Epoch 37/50\n",
      "208/208 [==============================] - 0s 648us/step - loss: 0.3442 - acc: 0.8654\n",
      "Epoch 38/50\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.3406 - acc: 0.8846\n",
      "Epoch 39/50\n",
      "208/208 [==============================] - 0s 491us/step - loss: 0.3282 - acc: 0.8798\n",
      "Epoch 40/50\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.3209 - acc: 0.8606\n",
      "Epoch 41/50\n",
      "208/208 [==============================] - 0s 645us/step - loss: 0.3262 - acc: 0.8702\n",
      "Epoch 42/50\n",
      "208/208 [==============================] - 0s 602us/step - loss: 0.3200 - acc: 0.8750\n",
      "Epoch 43/50\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.3115 - acc: 0.8606\n",
      "Epoch 44/50\n",
      "208/208 [==============================] - 0s 461us/step - loss: 0.3099 - acc: 0.8702\n",
      "Epoch 45/50\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.3017 - acc: 0.8990\n",
      "Epoch 46/50\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.2975 - acc: 0.9087\n",
      "Epoch 47/50\n",
      "208/208 [==============================] - 0s 527us/step - loss: 0.2960 - acc: 0.8990\n",
      "Epoch 48/50\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.2959 - acc: 0.8990\n",
      "Epoch 49/50\n",
      "208/208 [==============================] - 0s 482us/step - loss: 0.2907 - acc: 0.8894\n",
      "Epoch 50/50\n",
      "208/208 [==============================] - 0s 651us/step - loss: 0.2895 - acc: 0.8942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f96a09cf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is perform on original model, not on smaller or larger models.\n",
    "network_return = create_baseline()\n",
    "network_return.fit(X, encoded_Y, epochs=50, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
